# -*- coding: utf-8 -*-
"""tiam.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wPYLEkeWzGYunqJ4ic9GYOiEZetPFId4
"""

#kifik tiam, hope spain was good
#sma3 ya damme, el code works, bass fi the hard part,actually understanding it
#fa 3tebre this green writing is your cheat sheet
#hayda el line le tahet hayde is used to download the libraries
!pip install -q google-cloud-vision facenet-pytorch torchvision opencv-python-headless tqdm pandas ipywidgets
#w halla2 men hone
import os, cv2, shutil, time
import numpy as np
import pandas as pd
from tqdm.auto import tqdm
from google.colab import drive
from IPython.display import display, Image as ColabImage, clear_output
import ipywidgets as widgets
from pathlib import Path
import torch
from PIL import Image
# InsightFace references removed. This Colab script can use Google Cloud Vision + facenet-pytorch instead.
# from insightface.app import FaceAnalysis
#la hone kel hole are importing the libraries, ya3ne awal shi nazallnehon men el internet
#ba3den we called them inside our code,
#libraries are premade tools, that help us during our project

# this line here is us locating our drive, since google collab can be directly connected,
#we just have to mount the drive, lah tle2e button on the left esmo files,
# w when you click it, 3ndk option to mount drive, please do it
drive.mount('/content/drive')

"""the following is the drive access part"""

#in my case ken fi 2 folders fa ratabton be my drive w i called them
#eza your pictures bel future are in another drrive folder, please mention them here
#w eza aktar men 2 folder, you need to add Folder_3 /4 /etc...
#basically what im trying to say that this is where our data lives
# BOTH folders contain event pictures
FOLDER_1 = "/content/drive/MyDrive/Colab Notebooks/data/Athlete_101_Reference"
FOLDER_2 = "/content/drive/MyDrive/Colab Notebooks/data/Event_Photos_Input"

OUTPUT_DIR = "/content/drive/MyDrive/Colab_Notebooks/data/Face_Match_Output"
os.makedirs(OUTPUT_DIR, exist_ok=True)#<---- this is our output file, eno wen you want the output to be in

print("EVENT FOLDER 1:", FOLDER_1)#<---this is to make sure that the path is correct
print("EVENT FOLDER 2:", FOLDER_2)#<--same
print("OUTPUT:", OUTPUT_DIR)#<---same


# InsightFace initialization removed. Use Google Cloud Vision for detection
print("Note: InsightFace usage removed. Use Google Cloud Vision for detection and facenet-pytorch for embeddings in this notebook/script.")

#so images come in all shapes and forms, depending 3al camera aw wtvr format each phone chooses
#this section is basically loading all images, in all types

VALID_EXT = {".jpg",".jpeg",".png",".webp",".bmp"}#<--- the types

def scan_images(folder): #<--- this is a function that will find all images in a folder
    imgs=[]
    for r,_,files in os.walk(folder):
        for f in files:
            if os.path.splitext(f)[1].lower() in VALID_EXT:
                imgs.append(os.path.join(r,f))
    return sorted(imgs)

FOLDER1_IMAGES = scan_images(FOLDER_1) #<-- using the function to scan folder 1
FOLDER2_IMAGES = scan_images(FOLDER_2) #<-- same but for folder two

ALL_IMAGES = FOLDER1_IMAGES + FOLDER2_IMAGES #<-- now logically i want them all, so all images is 1+2

print("Folder 1 images:", len(FOLDER1_IMAGES))#<-- kel shi print is just debuggin
print("Folder 2 images:", len(FOLDER2_IMAGES)) #<-- ma lah ellik kel marra
print("TOTAL IMAGES LOADED:", len(ALL_IMAGES))#<-- but basically these are for us to make sure things are working

def load_bgr(path): #<-- we are loading the images in all colors
    try:
        with open(path,'rb') as f:
            arr=np.frombuffer(f.read(),np.uint8)
        return cv2.imdecode(arr,cv2.IMREAD_COLOR)
    except:
        return None

def resize_max(img,max_dim=1280): #<-- resizing all images so that our model works
    h,w=img.shape[:2]
    if max(h,w)<=max_dim: return img
    s=max_dim/max(h,w)
    return cv2.resize(img,(int(w*s),int(h*s)))

def get_faces(img): # <-- we are using insight to get all faces
    faces=[]
    for f in app.get(img):
        faces.append({
            "bbox"      : f.bbox.astype(int),
            "embedding" : f.normed_embedding.astype(np.float32),
            "score"     : float(f.det_score)
        }) #<-- i will elaborate on this more under this cell
    return faces

def cosine(a,b):#<-- now this is the actual algorithm that matches the faces
    a=a/(np.linalg.norm(a)+1e-9)
    b=b/(np.linalg.norm(b)+1e-9)
    return float(np.dot(a,b))

"""so now to discuss the actual math that took place,
awal shi
each image is basically a bunch of numbers, aka ente bta3rfiyon as pixels, each pixel is a combination of three colors (Red Green Blue) aka RGB, what we are doing is using insight to scan for facecs, Insight returns in our case three values:


1.   a bounding box value
2.   Embedding
3.   and a confidence score

hl2 the bounding box is an interval that decides where the face exists
the embedding is are the characteristics of the face, it the actual identity that we are using to match the faces sawa, wejjik 3ndo a unique face structure so it has a unique ratio, aka a unique embedding, the actual math of it is shway complex, ma lah fawtik fiyon, bass le bedde yeke tefhami is that we are taking the characteritics w sammayne embedding
ekhir shi el score is basically how sure we are men hakiyna, the closer to 1 the better, the closer to 0 the worst.

bel function te3it el cosine, le 3m bisir howe 3m menjib el embedding and comparing it to each and every face we found in all the photos,
w ma ba3rif eza zekra saff el vectors bel madrasse, bass mna3mil shi esmo dot product, bass instead of a 2d vector we are doing a multi dimensional matrix, again el math is shway complex, bass le lezim tefhami eno we are computing shi esmo cosine similarity ben 2 embeddings (our reference face and the other faces)

the reference face will be chosen in the next cell

"""

#hl2 this part is me being a little extra, 3melet gui for u to choose and crop 3a zaw2ik,
#bass collab shway limited fa this is the best i could do in scone (currently 3m beshrab caramel latte, shi ma tekhlass bwa2if sheghel)
#what you do here is simple, you start by choosing a picture with our target face, later fina na3mella eno yeftah camera w yekhod soura
# bass for now choose any picture be alba el target that we want to find, then you crop to find only his face
# this works even eza 3ndk kazza face btw, so ta3 n2ul el coach w el walad lah sammi "Zulfiqar" (bta3rfe eno shi3a w hek)
# bedde kel suwar te3 el coach w zulfiqar, ba3mil crop la hole el wejjen w then i find all pictures that hole el tnen jouweton
#now cropping shway sa2il, bass basically choose the interval te3 x and y, law we are using shi gheir collab
#kenet 3melta be tari2a aryah, bass el zebde hiye eno x ya3ne yamil w shmel, y ya3ne fo2 w tahet
PAGE_SIZE = 20
GRID_COLS = 4

num_images = len(ALL_IMAGES)
num_pages = max(1, (num_images + PAGE_SIZE - 1)//PAGE_SIZE)

gallery_out = widgets.Output()
crop_out = widgets.Output()

ref_embedding = None
_cached_full = {}

page = widgets.IntText(value=1, description="Page:", layout=widgets.Layout(width="150px"))
lbl  = widgets.Label(f"/ {num_pages}")
prev_btn = widgets.Button(description="‚üµ Prev", layout=widgets.Layout(width="90px"))
next_btn = widgets.Button(description="Next ‚ü∂", layout=widgets.Layout(width="90px"))


def show_page(i):
    gallery_out.clear_output()
    with gallery_out:
        i = max(1, min(num_pages, i))
        page.value = i

        start = (i-1)*PAGE_SIZE
        end   = min(num_images, start+PAGE_SIZE)

        print(f"Showing {start+1} ‚Üí {end} / {num_images}")

        rows=[]
        row=[]

        for idx in range(start,end):

            img_path = ALL_IMAGES[idx]
            img = load_bgr(img_path)
            if img is None:
                continue

            full  = resize_max(img,1024)
            thumb = resize_max(img,256)

            _cached_full[img_path] = full

            ok, buf = cv2.imencode(".jpg", thumb)

            im = widgets.Image(value=buf.tobytes(), format='jpg', width=200)
            bt = widgets.Button(description=f"CROP #{idx+1}", layout=widgets.Layout(width="160px"))

            def click_handler(b, p=img_path):
                open_crop_ui(p)

            bt.on_click(click_handler)

            row.append(widgets.VBox([im, bt]))
            if len(row)==GRID_COLS:
                rows.append(widgets.HBox(row))
                row=[]

        if row:
            rows.append(widgets.HBox(row))

        display(widgets.VBox(rows))

def open_crop_ui(path):
    crop_out.clear_output()
    with crop_out:
        print("üñº Cropping:", path)

        img=_cached_full[path]
        H,W=img.shape[:2]

        ok,buf=cv2.imencode(".jpg",img)
        display(ColabImage(data=buf))

        xs=widgets.IntRangeSlider(value=[W//4,W*3//4], min=0,max=W, description="X:",layout=widgets.Layout(width="600px"))
        ys=widgets.IntRangeSlider(value=[H//4,H*3//4], min=0,max=H, description="Y:",layout=widgets.Layout(width="600px"))

        preview=widgets.Output()
        confirm=widgets.Button(description="üéØ SET FACE", button_style="success")

        def update(_=None):
            preview.clear_output()
            with preview:
                x1,x2=xs.value; y1,y2=ys.value
                crop=img[y1:y2, x1:x2]
                ok,bf=cv2.imencode(".jpg",crop)
                display(ColabImage(data=bf))

        def set_ref(_):
            global ref_embedding
            x1,x2=xs.value; y1,y2=ys.value
            crop=img[y1:y2, x1:x2]
            faces=get_faces(crop)
            if not faces:
                print("‚ùå No face detected")
                return
            best=max(faces, key=lambda f:(f["bbox"][2]-f["bbox"][0])*(f["bbox"][3]-f["bbox"][1]))
            emb=best["embedding"]
            ref_embedding = emb/(np.linalg.norm(emb)+1e-9)
            print("\nüéØ REFERENCE FACE SET ‚Äî RUN MATCHING NOW\n")

        xs.observe(update,names="value")
        ys.observe(update,names="value")
        display(xs); display(ys); display(preview); update()
        display(confirm)
        confirm.on_click(set_ref)


prev_btn.on_click(lambda _:show_page(page.value-1))
next_btn.on_click(lambda _:show_page(page.value+1))
page.observe(lambda ch: show_page(ch["new"]), names="value")

display(widgets.HBox([prev_btn, page, lbl, next_btn]))
display(gallery_out)
display(crop_out)

show_page(1)

#after cropping the face, it will move to each and every picture and compare
#it will then save the info in a csv file bel drive
SIM_THRESHOLD = 0.35
BATCH = 128

run_btn = widgets.Button(description=" RUN MATCHING", button_style="warning")
run_out = widgets.Output()

display(run_btn)
display(run_out)

def run_matching(_):
    run_out.clear_output()
    with run_out:
        global ref_embedding
        if ref_embedding is None:
            print("‚ùó No reference face selected.")
            return

        targets = ALL_IMAGES
        total=len(targets)

        print(f"üîç Matching against {total} pictures")
        results=[]
        pbar=tqdm(total=total)

        for st in range(0,total,BATCH):
            subset=targets[st:st+BATCH]
            for p in subset:
                img=load_bgr(p)
                if img is None:
                    results.append({"image_path":p,"max_similarity":0,"faces":0})
                    pbar.update(1); continue

                faces=get_faces(resize_max(img))
                if not faces:
                    results.append({"image_path":p,"max_similarity":0,"faces":0})
                    pbar.update(1); continue

                sims=[cosine(ref_embedding,f["embedding"]) for f in faces]
                results.append({
                    "image_path":p,
                    "max_similarity":max(sims),
                    "faces":len(faces)
                })
                pbar.update(1)

        pbar.close()
        df=pd.DataFrame(results)
        df["is_match"]=(df["max_similarity"]>=SIM_THRESHOLD).astype(int)

        csv_path=os.path.join(OUTPUT_DIR,"matches.csv")
        df.to_csv(csv_path,index=False)

        print("\n‚úÖ DONE")
        print("üìÑ CSV:",csv_path)
        print("üéØ MATCHED:",df['is_match'].sum(),"/",len(df))

run_btn.on_click(run_matching)

#hl2 ana hone shway tfananet w 3melta eno ba3ed ma ile2e all photos, ikhaline ekhla2 folder bel esem le badde yeh
# w ihot kel el souwar honeek, heke bteb3ate la kel wahad souwaro bel drive link

label=widgets.Label("üìÅ Enter export folder name:")
name_box=widgets.Text(value="matched_photos")

export_btn=widgets.Button(description="üìÇ EXPORT", button_style="info")
export_out=widgets.Output()

display(label, name_box, export_btn, export_out)

def export_matches(_):
    export_out.clear_output()
    with export_out:

        folder=name_box.value.strip()
        if folder=="": print("‚ùó Empty name"); return

        csv_path=os.path.join(OUTPUT_DIR,"matches.csv")
        if not os.path.exists(csv_path):
            print("‚ùó Run matching first"); return

        df=pd.read_csv(csv_path)
        m=df[df["is_match"]==1]

        outdir=os.path.join(OUTPUT_DIR,folder)
        os.makedirs(outdir,exist_ok=True)

        print(f"üì∏ Exporting {len(m)} images ‚Üí {outdir}")

        for _,r in tqdm(m.iterrows(), total=len(m)):
            src=r["image_path"]
            fname=Path(src).name
            dst=os.path.join(outdir,fname)

            if os.path.exists(dst):
                stem,ext=os.path.splitext(fname)
                i=1
                while True:
                    new=f"{stem}_{i}{ext}"
                    if not os.path.exists(os.path.join(outdir,new)):
                        dst=os.path.join(outdir,new); break
                    i+=1

            shutil.copy2(src,dst)

        print("‚úÖ EXPORT COMPLETE")

export_btn.on_click(export_matches)

#this line is to read cosine similarity score and faces detected, some nerd shit, bass useful shit
#this is basically what the computer 3m byefham w ya3mil, faces is how many faces fi bel soura
#is_match ya3ne eza el zalame te3na bel soura

pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data/Face_Match_Output/matches.csv").head()

len(ALL_IMAGES), ALL_IMAGES[:5] #<-- hayde kenet 3m bshuf adde fi photos bel folders

"""mabrouk and good luck"""